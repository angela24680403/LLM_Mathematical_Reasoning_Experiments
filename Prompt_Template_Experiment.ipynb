{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOq9ApWDptDdvnc0ydPQBbA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ef9badad5624568839a1f7fffda3c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31cfcbb55e63493e92a72420cff6f8b6",
              "IPY_MODEL_826c8846a6ee40baaaaaf93536c59f93",
              "IPY_MODEL_c95425817c3744a2bf1cf4463b757fb5"
            ],
            "layout": "IPY_MODEL_f339e76db75a4962869199212b33427a"
          }
        },
        "31cfcbb55e63493e92a72420cff6f8b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14ea052db8c04992a2d0f6cf0d3bb8e6",
            "placeholder": "​",
            "style": "IPY_MODEL_0738fd2ea6bd443ab0fa8e1a5f18cd24",
            "value": ""
          }
        },
        "826c8846a6ee40baaaaaf93536c59f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_206180ef89bc48aca3a695826437d9f4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e43be49494b4cd3aa694a6eaf58c014",
            "value": 1
          }
        },
        "c95425817c3744a2bf1cf4463b757fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf86b6961279446db7eb9726fb8b4fa7",
            "placeholder": "​",
            "style": "IPY_MODEL_cc4b0b5c8b194493b1baeab74473be32",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00&lt;00:00,  1.59it/s]\n"
          }
        },
        "f339e76db75a4962869199212b33427a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14ea052db8c04992a2d0f6cf0d3bb8e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0738fd2ea6bd443ab0fa8e1a5f18cd24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "206180ef89bc48aca3a695826437d9f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e43be49494b4cd3aa694a6eaf58c014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf86b6961279446db7eb9726fb8b4fa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc4b0b5c8b194493b1baeab74473be32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b2328bcd4d14a40af3f73906fcf44ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ecd873a9bccb4b0981d41f90fdc723e6",
              "IPY_MODEL_8d431b451665472f9c90a19d4b5f776e",
              "IPY_MODEL_8be87d38c16f468880a0d328b7366165"
            ],
            "layout": "IPY_MODEL_47b85338de6b4529b2bdf89db5601f9f"
          }
        },
        "ecd873a9bccb4b0981d41f90fdc723e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4a0c21431a74ce89922ff24032a150f",
            "placeholder": "​",
            "style": "IPY_MODEL_12e53f257bc5474890ef446fcf9565ba",
            "value": ""
          }
        },
        "8d431b451665472f9c90a19d4b5f776e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eae104bfe80e4e14ac0db65835349588",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32bd3f3bb54a4f1c968d95d7782417d5",
            "value": 1
          }
        },
        "8be87d38c16f468880a0d328b7366165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd062e38a4a44a778913624a7254b5f2",
            "placeholder": "​",
            "style": "IPY_MODEL_c8f0badbc7274f7680867b0890587709",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00&lt;00:00,  1.37it/s]\n"
          }
        },
        "47b85338de6b4529b2bdf89db5601f9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4a0c21431a74ce89922ff24032a150f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12e53f257bc5474890ef446fcf9565ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eae104bfe80e4e14ac0db65835349588": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32bd3f3bb54a4f1c968d95d7782417d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd062e38a4a44a778913624a7254b5f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8f0badbc7274f7680867b0890587709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angela24680403/LLM_Mathematical_Reasoning_Experiments/blob/main/Prompt_Template_Experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0SX9pe9OWRcg"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth vllm\n",
        "else:\n",
        "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
        "    !pip install --no-deps unsloth vllm\n",
        "    # ==0.7.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Colab Extra Install { display-mode: \"form\" }\n",
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth vllm\n",
        "else:\n",
        "    !pip install --no-deps unsloth vllm==0.7.3\n",
        "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
        "    # Skip restarting message in Colab\n",
        "    import sys, re, requests; modules = list(sys.modules.keys())\n",
        "    for x in modules: sys.modules.pop(x) if \"PIL\" in x or \"google\" in x else None\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft \"trl==0.15.2\" triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "\n",
        "    # vLLM requirements - vLLM breaks Colab due to reinstalling numpy\n",
        "    f = requests.get(\"https://raw.githubusercontent.com/vllm-project/vllm/refs/heads/main/requirements/common.txt\").content\n",
        "    with open(\"vllm_requirements.txt\", \"wb\") as file:\n",
        "        file.write(re.sub(rb\"(transformers|numpy|xformers)[^\\n]{1,}\\n\", b\"\", f))\n",
        "    !pip install -r vllm_requirements.txt"
      ],
      "metadata": {
        "id": "y52Q6vY2WlVd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
        "import torch\n",
        "max_seq_length = 16384 # Can increase for longer reasoning traces\n",
        "lora_rank = 64 # Larger rank = smarter, but slower\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    load_in_4bit = True, # False for LoRA 16bit\n",
        "    fast_inference = True, # Enable vLLM fast inference\n",
        "    max_lora_rank = lora_rank,\n",
        "    gpu_memory_utilization = 0.5,# Reduce if out of memory\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969,
          "referenced_widgets": [
            "0ef9badad5624568839a1f7fffda3c7a",
            "31cfcbb55e63493e92a72420cff6f8b6",
            "826c8846a6ee40baaaaaf93536c59f93",
            "c95425817c3744a2bf1cf4463b757fb5",
            "f339e76db75a4962869199212b33427a",
            "14ea052db8c04992a2d0f6cf0d3bb8e6",
            "0738fd2ea6bd443ab0fa8e1a5f18cd24",
            "206180ef89bc48aca3a695826437d9f4",
            "9e43be49494b4cd3aa694a6eaf58c014",
            "cf86b6961279446db7eb9726fb8b4fa7",
            "cc4b0b5c8b194493b1baeab74473be32",
            "1b2328bcd4d14a40af3f73906fcf44ff",
            "ecd873a9bccb4b0981d41f90fdc723e6",
            "8d431b451665472f9c90a19d4b5f776e",
            "8be87d38c16f468880a0d328b7366165",
            "47b85338de6b4529b2bdf89db5601f9f",
            "d4a0c21431a74ce89922ff24032a150f",
            "12e53f257bc5474890ef446fcf9565ba",
            "eae104bfe80e4e14ac0db65835349588",
            "32bd3f3bb54a4f1c968d95d7782417d5",
            "fd062e38a4a44a778913624a7254b5f2",
            "c8f0badbc7274f7680867b0890587709"
          ]
        },
        "id": "ELPWzFIAWooY",
        "outputId": "8ff74e5a-eb02-42d7-d3b6-3c79c15cee41"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Switching from Unsloth dynamic quant to normal quant since\n",
            "we do not yet support fast inference for unsloth/deepseek-r1-distill-qwen-1.5b-unsloth-bnb-4bit\n",
            "==((====))==  Unsloth 2025.5.9: Fast Qwen2 patching. Transformers: 4.52.3. vLLM: 0.7.3.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: vLLM loading unsloth/deepseek-r1-distill-qwen-1.5b-bnb-4bit with actual GPU utilization = 16.2%\n",
            "Unsloth: Your GPU has CUDA compute capability 8.9 with VRAM = 22.16 GB.\n",
            "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 16384. Num Sequences = 128.\n",
            "Unsloth: vLLM's KV Cache can use up to 1.82 GB. Also swap space = 4 GB.\n",
            "INFO 06-06 09:20:09 config.py:549] This model supports multiple tasks: {'score', 'generate', 'embed', 'classify', 'reward'}. Defaulting to 'generate'.\n",
            "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'bfloat16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection'], 'llm_int8_threshold': 6.0}\n",
            "INFO 06-06 09:20:09 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='unsloth/deepseek-r1-distill-qwen-1.5b-bnb-4bit', speculative_config=None, tokenizer='unsloth/deepseek-r1-distill-qwen-1.5b-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=16384, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/deepseek-r1-distill-qwen-1.5b-bnb-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":0,\"backend\":\"inductor\",\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"debug\":false,\"dce\":true,\"coordinate_descent_tuning\":true,\"trace.enabled\":false,\"trace.graph_diagram\":false,\"triton.cudagraphs\":true,\"compile_threads\":48,\"max_autotune\":false,\"disable_progress\":false,\"verbose_progress\":true},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":128}, use_cached_outputs=False, \n",
            "INFO 06-06 09:20:12 model_runner.py:1110] Starting to load model unsloth/deepseek-r1-distill-qwen-1.5b-bnb-4bit...\n",
            "INFO 06-06 09:20:12 loader.py:1089] Loading weights with BitsAndBytes quantization.  May take a while ...\n",
            "INFO 06-06 09:20:13 weight_utils.py:254] Using model weights format ['*.safetensors']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ef9badad5624568839a1f7fffda3c7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b2328bcd4d14a40af3f73906fcf44ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 06-06 09:20:15 model_runner.py:1115] Loading model weights took 1.5052 GB\n",
            "INFO 06-06 09:20:18 worker.py:267] Memory profiling takes 2.23 seconds\n",
            "INFO 06-06 09:20:18 worker.py:267] the current vLLM instance can use total_gpu_memory (22.16GiB) x gpu_memory_utilization (0.16) = 3.59GiB\n",
            "INFO 06-06 09:20:18 worker.py:267] model weights take 1.51GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.08GiB; the rest of the memory reserved for KV Cache is 1.00GiB.\n",
            "INFO 06-06 09:20:19 executor_base.py:111] # cuda blocks: 2348, # CPU blocks: 9362\n",
            "INFO 06-06 09:20:19 executor_base.py:116] Maximum concurrency for 16384 tokens per request: 2.29x\n",
            "INFO 06-06 09:20:19 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Capturing CUDA graph shapes:   0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "Capturing CUDA graph shapes:   5%|▌         | 1/19 [00:01<00:28,  1.57s/it]\u001b[A\n",
            "Capturing CUDA graph shapes:  11%|█         | 2/19 [00:03<00:26,  1.57s/it]\u001b[A\n",
            "Capturing CUDA graph shapes:  16%|█▌        | 3/19 [00:04<00:25,  1.57s/it]\u001b[A\n",
            "Capturing CUDA graph shapes:  21%|██        | 4/19 [00:06<00:23,  1.58s/it]\u001b[A\n",
            "Capturing CUDA graph shapes:  26%|██▋       | 5/19 [00:07<00:22,  1.59s/it]\u001b[A\n",
            "Capturing CUDA graph shapes:  32%|███▏      | 6/19 [00:09<00:20,  1.59s/it]\u001b[A\n",
            "Capturing CUDA graph shapes:  37%|███▋      | 7/19 [00:11<00:18,  1.58s/it]\u001b[A\n",
            "Capturing CUDA graph shapes:  42%|████▏     | 8/19 [00:12<00:17,  1.59s/it]\u001b[A\n",
            "Capturing CUDA graph shapes:  47%|████▋     | 9/19 [00:14<00:15,  1.58s/it]\u001b[A\n",
            "Capturing CUDA graph shapes:  53%|█████▎    | 10/19 [00:15<00:14,  1.60s/it]\u001b[A\n",
            "Capturing CUDA graph shapes:  58%|█████▊    | 11/19 [00:17<00:12,  1.60s/it]\u001b[A\n",
            "Capturing CUDA graph shapes:  63%|██████▎   | 12/19 [00:19<00:11,  1.60s/it]\u001b[A\n",
            "Capturing CUDA graph shapes:  68%|██████▊   | 13/19 [00:20<00:09,  1.59s/it]\u001b[A\n",
            "Capturing CUDA graph shapes:  74%|███████▎  | 14/19 [00:22<00:07,  1.59s/it]\u001b[A\n",
            "Capturing CUDA graph shapes:  79%|███████▉  | 15/19 [00:23<00:06,  1.59s/it]\u001b[A\n",
            "Capturing CUDA graph shapes:  84%|████████▍ | 16/19 [00:25<00:04,  1.58s/it]\u001b[A\n",
            "Capturing CUDA graph shapes:  89%|████████▉ | 17/19 [00:26<00:03,  1.58s/it]\u001b[A\n",
            "Capturing CUDA graph shapes:  95%|█████████▍| 18/19 [00:28<00:01,  1.58s/it]\u001b[A\n",
            "Capturing CUDA graph shapes: 100%|██████████| 19/19 [00:30<00:00,  1.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 06-06 09:20:49 model_runner.py:1562] Graph capturing finished in 30 secs, took 0.06 GiB\n",
            "INFO 06-06 09:20:49 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 33.47 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Just some info: will skip parsing ['q_norm', 'pre_feedforward_layernorm', 'k_norm', 'post_feedforward_layernorm']\n",
            "Unsloth: Just some info: will skip parsing ['q_norm', 'pre_feedforward_layernorm', 'k_norm', 'post_feedforward_layernorm']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_boxed_value(text):\n",
        "    # Use regular expression to find the value inside \\boxed{}\n",
        "    pattern = r'\\\\boxed{([^}]*)}'\n",
        "    match = re.search(pattern, text)\n",
        "\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "Ht2HbrR4XKTp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXNYh3LkWrab",
        "outputId": "c49df508-71cd-480e-99eb-060140134308"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.32.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Dataset"
      ],
      "metadata": {
        "id": "dq-u-DBqWr-4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    aime24 = load_dataset(\"simplescaling/aime24_nofigures\", revision=\"main\")['train']\n",
        "    print(\"Dataset loaded successfully with revision 'main'\")\n",
        "except Exception as e:\n",
        "    print(f\"Loading with revision 'main' failed: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD101TADW7wo",
        "outputId": "16f34625-1933-4d51-9eaf-117c34f0f12a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully with revision 'main'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import SamplingParams\n",
        "sampling_params = SamplingParams(\n",
        "    temperature = 0.0,\n",
        "    max_tokens = max_seq_length,\n",
        ")"
      ],
      "metadata": {
        "id": "g6lx8CXpW8lX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYS_PROMPT1 = \"\"\"\n",
        "Solve the following math problem efficiently and clearly.\n",
        "The last line of your response should be of the following\n",
        "format: ’Therefore, the final answer is: $\\boxed{ANSWER}$.\n",
        "I hope it is correct’ (withoutquotes) where ANSWER is just\n",
        "the final number or expression that solves the problem.\n",
        "Think step by step before answering.\\n\n",
        "\"\"\"\n",
        "\n",
        "SYS_PROMPT2 = \"\"\"\n",
        "Act as a highly intelligent student who is very good at answering exam math questions.\n",
        "Your audience is a teacher who is marking the exam, looking for the correct working out and answer to the maths problem.\n",
        "The last line of your response should be of the following\n",
        "format: ’Therefore, the final answer is: $\\boxed{ANSWER}$.\n",
        "I hope it is correct’. Be logical concise in the reasoning process.\n",
        "\"\"\"\n",
        "\n",
        "SYS_PROMPT3 = \"\"\"\n",
        "Act as a highly intelligent student who is very good at answering exam math questions.\n",
        "Your audience is a teacher who is marking the exam, looking for the correct working out and answer to the maths problem.\n",
        "Be logical concise in the reasoning process.\n",
        "Please extract the question-solving information related to the problem. Only extract the most useful information, list them one by one!\n",
        "Please understand the information extracted from the maths problem,then solve the question step by step and\n",
        "show the answer.\n",
        "The last line of your response should be of the following\n",
        "format: ’Therefore, the final answer is: $\\boxed{ANSWER}$.\n",
        "I hope it is correct’.\n",
        "\"\"\"\n",
        "\n",
        "sys_prompts = [SYS_PROMPT1, SYS_PROMPT2, SYS_PROMPT3]"
      ],
      "metadata": {
        "id": "uYEfdffIXAPR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pretrained_outputs = []\n",
        "answers = []\n",
        "example = aime24[5]\n",
        "for sys_prompt in sys_prompts:\n",
        "    text = tokenizer.apply_chat_template([\n",
        "        {'role': 'system', 'content': sys_prompt},\n",
        "        {\"role\" : \"user\", \"content\" : example['problem']},\n",
        "    ], tokenize = False, add_generation_prompt = True)\n",
        "\n",
        "    output = model.fast_generate(\n",
        "      [text],\n",
        "      sampling_params = sampling_params,\n",
        "      lora_request = None,\n",
        "      )[0].outputs[0].text\n",
        "    pretrained_outputs.append(output)\n",
        "    answers.append(extract_boxed_value(output))\n",
        "\n",
        "print(\"The correct answer: \" + example['answer'])\n",
        "print(\"Generated answers: \" + str(answers))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzHL5f9HXyfd",
        "outputId": "7d1cb96d-8654-46af-ff33-58b29312da07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A"
          ]
        }
      ]
    }
  ]
}